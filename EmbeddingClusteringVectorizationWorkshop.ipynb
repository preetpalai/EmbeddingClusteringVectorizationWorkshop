{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "832c238b",
   "metadata": {},
   "source": [
    "# Embedding Clustering and Vectorization Workshop\n",
    "\n",
    "This notebook demonstrates the implementation of Word2Vec and GloVe embedding models on a real-world text corpus relevant to our final project.\n",
    "\n",
    "## Team Members\n",
    "- Kapil\n",
    "- Parag\n",
    "- Preetpal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429cba3",
   "metadata": {},
   "source": [
    "## üîÑ NLP Preprocessing Pipeline\n",
    "Steps:\n",
    "1. Document collection\n",
    "2. Tokenization\n",
    "3. Lowercasing\n",
    "4. Stopword removal\n",
    "5. Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cebd35",
   "metadata": {},
   "source": [
    "## 1.1 Document Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684fa4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading corupus for Titanic and Titan ship which sank in last century\n",
    "with open(\"./data/Corpus_Titanic.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_corpus = file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1dd27",
   "metadata": {},
   "source": [
    "## 1.2 Preprocessing (Tokenization, Lowercase, Stopword Removal, Lemmatization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f1e1351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['titanic', 'massive', 'passenger', 'liner', 'sank', 'north', 'atlantic', 'ocean', 'hitting', 'iceberg', 'people', 'died', 'one', 'deadliest', 'commercial', 'peacetime', 'maritime', 'disaster', 'modern', 'history', 'titanic', 'considered', 'unsinkable', 'nature', 'proved', 'otherwise', 'century', 'later', 'submersible', 'named', 'titan', 'imploded', 'descending', 'titanic', 'wreck', 'site', 'titan', 'privatelyoperated', 'deepsea', 'vehicle', 'designed', 'underwater', 'exploration', 'tragically', 'five', 'people', 'onboard', 'killed', 'titan', 'disappearance']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\acer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\acer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\acer/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Setup\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stopwords.words(\"english\")]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return tokens\n",
    "\n",
    "tokens = preprocess(raw_corpus)\n",
    "print(tokens[:50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d40562",
   "metadata": {},
   "source": [
    "# Step 2: Word2Vec Embedding (Predictive Model)\n",
    "\n",
    "## 2.1 Prepare Sentences for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfc420dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# If needed: simple sentence split for training\n",
    "sentences = [tokens[i:i+30] for i in range(0, len(tokens), 30)]\n",
    "\n",
    "# Train Word2Vec\n",
    "w2v_model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=2, sg=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02a4db",
   "metadata": {},
   "source": [
    "## 2.2 Get Similar Words to \"titanic\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9951d7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Similarity Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3ff0383f-86c3-47df-96e0-3f294db1f5bb",
       "rows": [
        [
         "0",
         "maritime",
         "0.21613891422748566"
        ],
        [
         "1",
         "massive",
         "0.0931011214852333"
        ],
        [
         "2",
         "later",
         "0.09291722625494003"
        ],
        [
         "3",
         "ocean",
         "0.07959061115980148"
        ],
        [
         "4",
         "people",
         "0.06285078823566437"
        ],
        [
         "5",
         "century",
         "0.027057457715272903"
        ],
        [
         "6",
         "deepsea",
         "0.016134677454829216"
        ],
        [
         "7",
         "titan",
         "-0.01083235815167427"
        ],
        [
         "8",
         "human",
         "-0.027654385194182396"
        ],
        [
         "9",
         "disaster",
         "-0.05234673246741295"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maritime</td>\n",
       "      <td>0.216139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>massive</td>\n",
       "      <td>0.093101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>later</td>\n",
       "      <td>0.092917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ocean</td>\n",
       "      <td>0.079591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>people</td>\n",
       "      <td>0.062851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>century</td>\n",
       "      <td>0.027057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepsea</td>\n",
       "      <td>0.016135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>titan</td>\n",
       "      <td>-0.010832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>human</td>\n",
       "      <td>-0.027654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>disaster</td>\n",
       "      <td>-0.052347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Similarity Score\n",
       "0  maritime          0.216139\n",
       "1   massive          0.093101\n",
       "2     later          0.092917\n",
       "3     ocean          0.079591\n",
       "4    people          0.062851\n",
       "5   century          0.027057\n",
       "6   deepsea          0.016135\n",
       "7     titan         -0.010832\n",
       "8     human         -0.027654\n",
       "9  disaster         -0.052347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w2v_similar = w2v_model.wv.most_similar(\"titanic\", topn=10)\n",
    "import pandas as pd\n",
    "df_w2v = pd.DataFrame(w2v_similar, columns=[\"Word\", \"Similarity Score\"])\n",
    "display(df_w2v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6148b590",
   "metadata": {},
   "source": [
    "## GloVe Implementation (Count-based Model)\n",
    "Note: We'll use the `glove_python` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "494cfe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Similarity Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "201a2eca-1150-4367-aea0-a7d96cb96313",
       "rows": [
        [
         "0",
         "maritime",
         "0.21613891422748566"
        ],
        [
         "1",
         "massive",
         "0.0931011214852333"
        ],
        [
         "2",
         "later",
         "0.09291722625494003"
        ],
        [
         "3",
         "ocean",
         "0.07959061115980148"
        ],
        [
         "4",
         "people",
         "0.06285078823566437"
        ],
        [
         "5",
         "century",
         "0.027057457715272903"
        ],
        [
         "6",
         "deepsea",
         "0.016134677454829216"
        ],
        [
         "7",
         "titan",
         "-0.01083235815167427"
        ],
        [
         "8",
         "human",
         "-0.027654385194182396"
        ],
        [
         "9",
         "disaster",
         "-0.05234673246741295"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maritime</td>\n",
       "      <td>0.216139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>massive</td>\n",
       "      <td>0.093101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>later</td>\n",
       "      <td>0.092917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ocean</td>\n",
       "      <td>0.079591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>people</td>\n",
       "      <td>0.062851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>century</td>\n",
       "      <td>0.027057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepsea</td>\n",
       "      <td>0.016135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>titan</td>\n",
       "      <td>-0.010832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>human</td>\n",
       "      <td>-0.027654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>disaster</td>\n",
       "      <td>-0.052347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Similarity Score\n",
       "0  maritime          0.216139\n",
       "1   massive          0.093101\n",
       "2     later          0.092917\n",
       "3     ocean          0.079591\n",
       "4    people          0.062851\n",
       "5   century          0.027057\n",
       "6   deepsea          0.016135\n",
       "7     titan         -0.010832\n",
       "8     human         -0.027654\n",
       "9  disaster         -0.052347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w2v_similar = w2v_model.wv.most_similar(\"titanic\", topn=10)\n",
    "import pandas as pd\n",
    "df_w2v = pd.DataFrame(w2v_similar, columns=[\"Word\", \"Similarity Score\"])\n",
    "display(df_w2v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec882b",
   "metadata": {},
   "source": [
    "# Step 3: GloVe Embedding (Count-Based Model)\n",
    "\n",
    "## 3.1 Load Pretrained GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c73a98fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "glove_model = api.load(\"glove-wiki-gigaword-100\")  # Or 50/200/300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7f8cd",
   "metadata": {},
   "source": [
    "## 3.2 Get Similar Words to \"titanic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "036de018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Similarity Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2eb0d766-1ed4-48cf-8ffc-9b3010d29f0f",
       "rows": [
        [
         "0",
         "sinking",
         "0.5609983801841736"
        ],
        [
         "1",
         "dicaprio",
         "0.5585139989852905"
        ],
        [
         "2",
         "rms",
         "0.5548851490020752"
        ],
        [
         "3",
         "voyage",
         "0.5363595485687256"
        ],
        [
         "4",
         "sunk",
         "0.5300329923629761"
        ],
        [
         "5",
         "epic",
         "0.5166837573051453"
        ],
        [
         "6",
         "starship",
         "0.5144163370132446"
        ],
        [
         "7",
         "winslet",
         "0.5132650136947632"
        ],
        [
         "8",
         "r.m.s.",
         "0.5079967975616455"
        ],
        [
         "9",
         "iceberg",
         "0.5048078298568726"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sinking</td>\n",
       "      <td>0.560998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dicaprio</td>\n",
       "      <td>0.558514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rms</td>\n",
       "      <td>0.554885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>voyage</td>\n",
       "      <td>0.536360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sunk</td>\n",
       "      <td>0.530033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>epic</td>\n",
       "      <td>0.516684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>starship</td>\n",
       "      <td>0.514416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>winslet</td>\n",
       "      <td>0.513265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r.m.s.</td>\n",
       "      <td>0.507997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iceberg</td>\n",
       "      <td>0.504808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Similarity Score\n",
       "0   sinking          0.560998\n",
       "1  dicaprio          0.558514\n",
       "2       rms          0.554885\n",
       "3    voyage          0.536360\n",
       "4      sunk          0.530033\n",
       "5      epic          0.516684\n",
       "6  starship          0.514416\n",
       "7   winslet          0.513265\n",
       "8    r.m.s.          0.507997\n",
       "9   iceberg          0.504808"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glove_similar = glove_model.most_similar(\"titanic\", topn=10)\n",
    "df_glove = pd.DataFrame(glove_similar, columns=[\"Word\", \"Similarity Score\"])\n",
    "display(df_glove)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f76c3",
   "metadata": {},
   "source": [
    "##  Talking Points: Word2Vec vs. GloVe\n",
    "\n",
    "\n",
    "| **Topic**                          | **Word2Vec**                                                       | **GloVe**                                                    |\n",
    "| ---------------------------------- | ------------------------------------------------------------------ | ------------------------------------------------------------ |\n",
    "| **Model Type**                     | Predictive                                                         | Count-based                                                  |\n",
    "| **Training Source**                | Trained on custom Titanic corpus                                   | Pre-trained on Wikipedia + Gigaword                          |\n",
    "| **Vocabulary Coverage**            | Limited to your dataset                                            | Very broad (global vocab)                                    |\n",
    "| **\"Titanic\" Similar Words Output** | Contextually relevant to Titanic (e.g., ‚Äúship‚Äù, ‚Äúpassenger‚Äù)       | Broader or more abstract terms based on global co-occurrence |\n",
    "| **Accuracy**                       | Context-sensitive, but can miss words not frequent in small corpus | Captures global word meaning well                            |\n",
    "| **Training Time**                  | Takes time based on data size                                      | Instant (pre-trained model)                                  |\n",
    "| **Customization**                  | Fully customizable                                                 | Not trainable (read-only)                                    |\n",
    "| **Memory Use**                     | Efficient for small corpora                                        | Larger model size (\\~800MB)                                  |\n",
    "| **Use Case Fit**                   | Best for domain-specific tasks                                     | Best for general NLP tasks                                   |\n",
    "| **Similarity Method**              | Cosine similarity on trained vectors                               | Cosine similarity on pre-trained vectors                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d8ffd",
   "metadata": {},
   "source": [
    "##  Summary\n",
    "- Implemented both predictive and count-based embedding models\n",
    "- Cleaned and tokenized real-world documents from our Grocery Buddies project\n",
    "- Compared GloVe vs Word2Vec in practical use cases\n",
    "- All members contributed equally to this collaborative peer-reviewed notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
